# HOLDSE Proper Base Configuration
# Use this as the template for production training

defaults:
  - sanity_check_fast

# ================================================================
# PHASE 3: GHOP Integration (Properly Configured)
# ================================================================
phase3:
  enabled: true
  use_modular_init: true

  ghop:
    unified_checkpoint: "checkpoints/ghop/last.ckpt"
    vqvae_checkpoint: "checkpoints/ghop/last.ckpt"
    unet_checkpoint: "checkpoints/ghop/last.ckpt"
    config_path: "checkpoints/ghop/config.yaml"
    vqvae_use_pretrained: true
    unet_use_pretrained: true
    device: "cuda"

  # CRITICAL: Immediate activation
  phase3_start_iter: 0      # Start immediately
  warmup_iters: 0           # No warmup delay
  w_sds: 5000.0
  sds_iters: 1              # Every step (for debugging)
  grid_resolution: 64       # Good quality
  spatial_lim: 1.5

  sds:
    diffusion_steps: 1000
    prediction_respacing: 10
    noise_schedule: "linear"
    min_step_ratio: 0.02
    max_step_ratio: 0.98
    guidance_scale: 4.0

# ================================================================
# PHASE 4: Contact Refinement
# ================================================================
phase4:
  enabled: true
  contact_start_iter: 500
  contact_duration: 100
  contact_warmup_iters: 50

  contact_refinement:
    enabled: true
    contact_thresh: 0.01
    collision_thresh: 0.005
    w_penetration: 50.0
    w_attraction: 5.0
    contact_zones: "zones"

  mesh_extraction:
    enabled: true
    resolution: 128
    threshold: 0.0
    extract_every: 1

  w_contact: 10.0
  log_contact_every: 10

# ================================================================
# PHASE 5: Advanced Features
# ================================================================
phase5:
  enabled: true
  phase5_start_iter: 100
  total_iterations: 1000
  warmup_iters: 0
  finetune_start_iter: 800

  temporal_window: 5
  w_velocity: 0.5
  w_acceleration: 0.1
  w_camera_motion: 0.3
  w_temporal: 1.0
  adaptive_weight: true

  guidance_scale: 4.0
  min_step: 0.02
  max_step: 0.98
  prediction_respacing: 100
  w_schedule: "dream"

  proximity_threshold: 0.015
  min_contact_verts: 5
  max_contact_verts: 50
  contact_update_freq: 10
  penalize_palm: true

  log_phase5_every: 10
  enable_geometry_sampling: false

# ================================================================
# PROPER MODEL ARCHITECTURE (256-dim networks!)
# ================================================================
model:
  implicit_network:
    feature_vector_size: 256      # INCREASED from 32
    d_in: 3
    d_out: 1
    dims: [256, 256, 256, 256]    # INCREASED from [32, 32]
    init: geometry
    bias: 0.6
    skip_in: [2]
    weight_norm: true
    multires: 6                    # INCREASED from 1
    cond: pose

  rendering_network:
    feature_vector_size: 256      # INCREASED from 32
    mode: pose
    d_in: 14
    d_out: 3
    dims: [256, 256, 256]         # INCREASED from [32]
    weight_norm: true
    multires_view: 4              # INCREASED from -1

  bg_implicit_network:
    feature_vector_size: 256      # INCREASED from 32
    d_in: 4
    d_out: 1
    dims: [256, 256]
    init: none
    bias: 0.0
    skip_in: []
    weight_norm: false
    multires: 6                    # INCREASED from 2
    cond: frame
    dim_frame_encoding: 32        # INCREASED from 8

  bg_rendering_network:
    feature_vector_size: 256      # INCREASED from 32
    mode: nerf_frame_encoding
    d_in: 3
    d_out: 3
    dims: [256, 256]              # INCREASED from [32]
    weight_norm: false
    multires_view: 4              # INCREASED from 1
    dim_frame_encoding: 32        # INCREASED from 8

  density:
    params_init:
      beta: 0.1
    beta_min: 0.0001

  ray_sampler:
    near: 0.0
    N_samples: 64                 # INCREASED from 8
    N_samples_eval: 128
    N_samples_extra: 32           # INCREASED from 4
    eps: 0.1
    beta_iters: 10                # INCREASED from 1
    max_total_iters: 5            # INCREASED from 1
    N_samples_inverse_sphere: 32  # INCREASED from 4

  sdf_bounding_sphere: 1.0

# ================================================================
# BALANCED LOSS WEIGHTS (CRITICAL!)
# ================================================================
loss:
  w_rgb: 10.0              # RGB loss weight
  w_mask: 5.0              # Mask loss
  w_mano_cano: 0.5         # REDUCED to prevent dominance
  w_eikonal: 0.1
  w_smooth: 0.01
  w_semantic: 1.0
  w_opacity_sparse: 0.1

# ================================================================
# TRAINING SETTINGS
# ================================================================
training:
  num_epochs: 100            # Will be modified by script
  max_steps: -1
  eval_every_epoch: 10
  log_every: 5
  gradient_clip: 1.0

# ================================================================
# DATASET
# ================================================================
dataset:
  train:
    type: "train"
    batch_size: 4          # Larger batch
    drop_last: false
    shuffle: true
    num_workers: 4         # Parallel loading
    pixel_per_batch: 2048  # More rays

  valid:
    type: "val"
    enabled: false
    batch_size: 1
    drop_last: false
    shuffle: false
    num_workers: 0
    pixel_per_batch: 512

  test:
    type: "test"
    batch_size: 1
    drop_last: false
    shuffle: false
    num_workers: 0
    pixel_per_batch: 8192

# ================================================================
# LOGGING
# ================================================================
logging:
  log_images_every: 50
  log_mesh_every: 500
  log_to_file: true
  verbose: true

# ================================================================
# VALIDATION
# ================================================================
validation:
  enabled: false

# ================================================================
# OPTIMIZER
# ================================================================
optimizer:
  lr: 0.0005             # Higher LR for larger networks
  type: "adam"
  weight_decay: 0.0

# ================================================================
# EXPERIMENT INFO
# ================================================================
experiment:
  name: 'ghop_production_bottle_1_v2'
  description: 'Production training with proper 256-dim networks and balanced losses'

# Disable validation (GHOP dataset compatibility)
trainer:
  limit_val_batches: 0
  num_sanity_val_steps: 0