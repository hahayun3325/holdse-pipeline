# ================================================================
# Stage 3: 30-Epoch Training with OOM Protection
# Phase Distribution: 2:1 ratio (Phase 3:Phase 4), Phase 5 minimal
# ================================================================

# ================================================================
# PHASE 3: SDS GUIDANCE (39,700 steps = 19.85 epochs)
# ================================================================
phase3:
  enabled: true

  # GHOP Checkpoints
  ghop:
    config_path: checkpoints/ghop/config.yaml
    device: cuda
    unet_checkpoint: /home/fredcui/Projects/ghop/output/joint_3dprior/mix_data/checkpoints/last.ckpt
    unified_checkpoint: /home/fredcui/Projects/ghop/output/joint_3dprior/mix_data/checkpoints/last.ckpt
    vqvae_checkpoint: /home/fredcui/Projects/ghop/output/joint_3dprior/mix_data/checkpoints/last.ckpt
    unet_use_pretrained: true
    vqvae_use_pretrained: true
    # ✅ NEW: Use Hugging Face CLIP instead of checkpoint CLIP
    use_huggingface_clip: true
    clip_model_name: "openai/clip-vit-large-patch14"  # Optional: default if not specified

  grid_resolution: 64
  spatial_lim: 1.5

  # Phase 3 Boundaries - 2/3 of training (40,000 steps)
  phase3_start_iter: 0
  phase3_end_iter: 34999         # ← CHANGED: End earlier for longer Phase 4

  # SDS Configuration - KEEP FROM STAGE 2
  sds:
    diffusion_steps: 1000
    guidance_scale: 3.0
    max_step_ratio: 0.98
    min_step_ratio: 0.02
    noise_schedule: linear
    prediction_respacing: 50

  sds_iters: 1
  use_modular_init: true

  w_sds_schedule:
    enabled: true
    step_0: 0.25
    step_5000: 0.25
    step_10000: 0.22             # ← Slower decay
    step_15000: 0.18
    step_20000: 0.15             # ← Higher than before
    step_25000: 0.12
    step_30000: 0.10
    step_34999: 0.04             # ← Minimal baseline (not 0)
    interpolation: "linear"

  diagnostics:
    rgb_convergence_check:
      enabled: true
      step: 20000
      threshold: 0.08
      warning_only: true
    sds_trend_check:
      enabled: true
      check_every: 1000
      window: 2000
      max_increase: 0.2
    log_sds_weight_every: 100

  warmup_iters: 0

# ================================================================
# PHASE 4: CONTACT REFINEMENT (19,500 steps = 9 epochs)
# ================================================================
phase4:
  enabled: true

  # Phase boundaries - 1/3 of training (19,800 steps)
  contact_start_iter: 35000      # ← CHANGED: Start earlier
  contact_end_iter: 59499       # End before Phase 5
  contact_warmup_iters: 1000     # ← CHANGED: Longer warmup

  # Thresholds
  contact_thresh: 0.20
  collision_thresh: 0.08

  # Contact weights
  w_contact: 0.5                 # ← changed from 1.5
  w_penetration: 50.0           # ← changed from 150
  w_attraction: 5.0             # ← changed from 15
  w_damping: 0.001               # ← ENABLED

  # Mesh extraction settings
  mesh_resolution: 256          # Marching cubes resolution
  mesh_padding: 0.1             # Padding around object bounds

  log_contact_every: 100

# ================================================================
# PHASE 5: TEMPORAL CONSISTENCY (500 steps = 0.25 epochs, FINAL ONLY)
# ================================================================
phase5:
  enabled: true

  # Minimal Phase 5 - last 500 steps only
  phase5_start_iter: 59500      # Start at epoch 29.75
  phase5_end_iter: 60000        # Explicit termination at training end

  # Scheduler configuration
  use_scheduler: true
  scheduler:
    total_iterations: 60000
    warmup_iters: 0
    phase3_start: 0
    phase4_start: 40000         # Match contact_start_iter
    phase5_start: 59500         # Match phase5_start_iter
    finetune_start: 59750       # 250 steps before end

  # Temporal weights - conservative
  w_temporal: 0.01
  w_velocity: 0.005
  w_acceleration: 0.005
  w_camera_motion: 0.001

  # Memory optimizations - CRITICAL for OOM prevention
  adaptive_contacts:
    enabled: false              # Disabled to save ~125 MB
    k_neighbors: 5
    contact_threshold: 0.10
    update_frequency: 50
    cache_size: 50

  temporal:
    history_size: 3             # Reduced from 10 to minimum (saves 70% memory)
    velocity_weight: 1.0
    acceleration_weight: 0.5

  log_phase5_every: 100

# ================================================================
# SCENE & MODEL (UNCHANGED FROM STAGE 2)
# ================================================================
scene_bounding_sphere: 6.0

# ================================================================
# MODEL CONFIGURATION (MUST MATCH STAGE 2 CHECKPOINT)
# ================================================================
model:
  # Density configuration
  density:
    params_init:
      beta: 0.1
    beta_min: 0.0001

  # Ray sampler configuration
  ray_sampler:
    near: 0.0
    N_samples: 64
    N_samples_eval: 128
    N_samples_extra: 32
    eps: 0.1
    beta_iters: 10
    max_total_iters: 5
    N_samples_inverse_sphere: 32
    add_tiny: 0.000001

  # Hand implicit network
  implicit_network:
    feature_vector_size: 256
    d_in: 3
    d_out: 1
    dims: [256, 256, 256, 256, 256, 256, 256, 256]
    init: geometry
    bias: 0.6
    skip_in: [4]
    weight_norm: true
    multires: 6
    cond: pose

  # Hand rendering network
  rendering_network:
    feature_vector_size: 256
    mode: pose
    d_in: 270
    d_out: 3
    dims: [256, 256, 256, 256]
    weight_norm: true
    multires_view: 0
    d_implicit_features: 256

  # Background implicit network
  bg_implicit_network:
    feature_vector_size: 256
    d_in: 4
    d_out: 1
    dims: [256, 256, 256, 256, 256, 256, 256, 256]
    init: none
    bias: 0.0
    skip_in: [4]
    weight_norm: false
    multires: 10
    cond: frame
    dim_frame_encoding: 32

  # Background rendering network
  bg_rendering_network:
    feature_vector_size: 256
    mode: nerf_frame_encoding
    d_in: 259
    d_out: 3
    dims: [128]
    weight_norm: false
    multires_view: 4
    dim_frame_encoding: 32
    multires_xyz: 42
    d_implicit_features: 171

# ================================================================
# DATASET CONFIGURATION (KEEP FROM STAGE 2)
# ================================================================
dataset:
  dataset_path: data/hold_MC1_ho3d/build
  seq_name: hold_MC1_ho3d

  train:
    type: train
    batch_size: 1
    drop_last: false
    shuffle: true
    num_workers: 4

  valid:
    type: val
    batch_size: 1
    drop_last: false
    shuffle: false
    pixel_per_batch: 512
    enabled: false

# ================================================================
# LOSS CONFIGURATION (UPDATED FOR STAGE 3)
# ================================================================
loss:
  w_rgb: 0.8                    # Keep base RGB loss
  w_mask: 0.5              # CHANGED: from 0.1
  w_mask_edge: 0.15         # NEW: Add this line
  w_eikonal: 0.8                # Keep SDF regularization
  w_smooth: 0.01               # Keep smoothness
  w_temporal: 1.0               # NEW: Temporal base weight
  rgb_loss_type: "l1"
  # NEW: Self-supervised geometry
  w_normal_consistency: 0.15
  w_depth_smoothness: 0.1
  w_chamfer: 0.05                    # ← CHANGED from w_template_chamfer
  chamfer_start_step: 15000            # ← NEW: Add this line!
  # ============================================================
  # Object Template Chamfer (NEW - Step 3A)
  # ============================================================
  w_obj_chamfer: 0.15              # Weight for object shape regularization
  obj_chamfer_start_step: 10000   # Start after SDS warmup (Phase 3)
  w_obj_generic: 0.05          # Generic prior fallback (weaker than template)
  w_obj_smoothness: 0.001

# ================================================================
# TRAINING CONFIGURATION - 30 EPOCHS
# ================================================================
training:
  num_epochs: 30
  max_steps: 60000
  eval_every_epoch: 999
  log_every: 50
  gradient_clip: 1.0

# ================================================================
# OPTIMIZER CONFIGURATION (KEEP FROM STAGE 2)
# ================================================================
optimizer:
  lr: 0.0001                    # Same learning rate as Stage 2
  type: "adam"
  weight_decay: 0.0
  betas: [0.9, 0.999]
  eps: 1.0e-08

# Learning rate scheduler - cosine annealing
scheduler:
  type: "cosine"
  T_max: 60000                  # Full 30 epochs
  eta_min: 0.00001              # 10× reduction
  warmup_steps: 2000            # 1 epoch warmup

# ================================================================
# EXPERIMENT CONFIGURATION
# ================================================================
experiment:
  name: 'stage3_30epoch_optimized_2to1_ratio'

# ================================================================
# CHECKPOINT
# ================================================================
checkpoint:
  # Load Stage 2 trained checkpoint
  resume_from: 'outputs/stage2_official_cb20a1702_FIXED/checkpoints/last.ckpt'
  load_optimizer: false
  load_scheduler: false

# ================================================================
# CALLBACKS - DUAL CHECKPOINT SYSTEM
# ================================================================
callbacks:
  # Epoch-based: Best model selection
  checkpoint:
    monitor: "train_loss"
    mode: "min"
    save_top_k: 3
    every_n_epochs: 5           # Save every 5 epochs (reduce frequency for 30 epochs)
    save_last: true
    dirpath: "checkpoints"
    filename: "epoch{epoch:02d}-loss{loss:.4f}"

  # Step-based checkpoint (saves every 500 steps)
  checkpoint_steps:
    monitor: null
    mode: "min"
    save_top_k: -1              # Save all step checkpoints
    every_n_train_steps: 500   # Save every steps for 30-epoch training
    save_last: false
    filename: "step{step:05d}"
    save_on_train_epoch_end: false
    verbose: true