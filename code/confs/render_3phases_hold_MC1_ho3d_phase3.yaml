# ================================================================
# Stage 3: Pure SDS Training - 80K Steps (40 Epochs)
# Phase Distribution: Phase 3 only (SDS Diffusion)
# ================================================================

# ================================================================
# PHASE 3: SDS GUIDANCE ONLY (80,000 steps = 40 epochs)
# ================================================================
phase3:
  enabled: false

  # GHOP Checkpoints
  ghop:
    config_path: checkpoints/ghop/config.yaml
    device: cuda
    unet_checkpoint: /home/fredcui/Projects/ghop/output/joint_3dprior/mix_data/checkpoints/last.ckpt
    unified_checkpoint: /home/fredcui/Projects/ghop/output/joint_3dprior/mix_data/checkpoints/last.ckpt
    vqvae_checkpoint: /home/fredcui/Projects/ghop/output/joint_3dprior/mix_data/checkpoints/last.ckpt
    unet_use_pretrained: true
    vqvae_use_pretrained: true
    use_huggingface_clip: true
    clip_model_name: "openai/clip-vit-large-patch14"

  grid_resolution: 64
  spatial_lim: 1.5

  # Phase 3 spans entire training
  phase3_start_iter: 0
  phase3_end_iter: 79999         # ← CHANGED: Entire 80K training

  # SDS Configuration - Refined based on Session 60-62
  sds:
    diffusion_steps: 1000
    guidance_scale: 3.0
    max_step_ratio: 0.98
    min_step_ratio: 0.02
    noise_schedule: linear
    prediction_respacing: 50

  sds_iters: 1
  use_modular_init: true

  # Extended weight schedule for 80K steps
  w_sds_schedule:
    enabled: true
    step_0: 0.30                 # ← Start higher for strong initial guidance
    step_10000: 0.28
    step_20000: 0.25
    step_30000: 0.22
    step_40000: 0.18             # ← Midpoint
    step_50000: 0.15
    step_60000: 0.12
    step_70000: 0.10
    step_79999: 0.08             # ← Maintain minimal baseline (don't go to 0)
    interpolation: "linear"

  diagnostics:
    rgb_convergence_check:
      enabled: true
      step: 30000                # Check at midpoint
      threshold: 0.08
      warning_only: true
    sds_trend_check:
      enabled: true
      check_every: 2000
      window: 5000
      max_increase: 0.2
    log_sds_weight_every: 200

  warmup_iters: 0

# ================================================================
# PHASE 4: CONTACT REFINEMENT (DISABLED)
# ================================================================
phase4:
  enabled: false                 # ← DISABLED: Contact loss stuck at 0.0

# ================================================================
# PHASE 5: TEMPORAL CONSISTENCY (DISABLED)
# ================================================================
phase5:
  enabled: false                 # ← DISABLED: Cannot skip Phase 4

# ================================================================
# SCENE & MODEL (UNCHANGED)
# ================================================================
scene_bounding_sphere: 6.0

model:
  density:
    params_init:
      beta: 0.1
    beta_min: 0.0001

  ray_sampler:
    near: 0.0
    N_samples: 64
    N_samples_eval: 128
    N_samples_extra: 32
    eps: 0.1
    beta_iters: 10
    max_total_iters: 5
    N_samples_inverse_sphere: 32
    add_tiny: 0.000001

  implicit_network:
    feature_vector_size: 256
    d_in: 3
    d_out: 1
    dims: [256, 256, 256, 256, 256, 256, 256, 256]
    init: geometry
    bias: 0.6
    skip_in: [4]
    weight_norm: true
    multires: 6
    cond: pose

  rendering_network:
    feature_vector_size: 256
    mode: pose
    d_in: 270
    d_out: 3
    dims: [256, 256, 256, 256]
    weight_norm: true
    multires_view: 0
    d_implicit_features: 256

  bg_implicit_network:
    feature_vector_size: 256
    d_in: 4
    d_out: 1
    dims: [256, 256, 256, 256, 256, 256, 256, 256]
    init: none
    bias: 0.0
    skip_in: [4]
    weight_norm: false
    multires: 10
    cond: frame
    dim_frame_encoding: 32

  bg_rendering_network:
    feature_vector_size: 256
    mode: nerf_frame_encoding
    d_in: 259
    d_out: 3
    dims: [128]
    weight_norm: false
    multires_view: 4
    dim_frame_encoding: 32
    multires_xyz: 42
    d_implicit_features: 171

# ================================================================
# DATASET CONFIGURATION
# ================================================================
dataset:
  dataset_path: data/hold_MC1_ho3d/build
  seq_name: hold_MC1_ho3d

  train:
    type: train
    batch_size: 1
    drop_last: false
    shuffle: true
    num_workers: 4

  valid:
    type: val
    batch_size: 1
    drop_last: false
    shuffle: false
    pixel_per_batch: 512
    enabled: false

  test:
    type: test
    batch_size: 1
    drop_last: false
    shuffle: false
    pixel_per_batch: 512

# ================================================================
# LOSS CONFIGURATION - Proven Working Losses Only
# ================================================================
loss:
  # Base losses - Balanced based on Session 60 findings
  w_rgb: 0.8                    # ← Primary photometric constraint
  w_mask: 0.5                    # ← Silhouette supervision
  w_mask_edge: 0.15              # ← Edge sharpness
  w_eikonal: 0.8                 # ← SDF regularization (reduced)
  w_smooth: 0.01                 # ← Surface smoothness
  rgb_loss_type: "l1"

  # Self-supervised geometry - DISABLED (problematic)
  w_normal_consistency: 0.15    # ← Ray rendering incompatible
  w_depth_smoothness: 0.1       # ← Per-ray depth incompatible

  # Hand Chamfer - KEEP (proven working in logs)
  w_chamfer: 0.05                # ← Increased from 0.05
  chamfer_start_step: 15000     # ← Earlier activation for 80K training

  # Object Chamfer - DISABLED (mesh extraction failing)
  w_obj_chamfer: 0.15
  obj_chamfer_start_step: 10
  w_obj_generic: 0.05
  w_obj_smoothness: 0.001       # ← Minimal vertex smoothness only

  # Temporal - Not used (Phase 5 disabled)
  w_temporal: 1.0

# ================================================================
# TRAINING CONFIGURATION - 40 EPOCHS (80K steps)
# ================================================================
training:
  num_epochs: 40                 # ← 40 epochs * 2000 steps = 80K
  max_steps: 80000               # ← Explicit step limit
  eval_every_epoch: 999          # ← Disable epoch-based eval
  log_every: 100                 # ← Log every 100 steps
  gradient_clip: 1.0

# ================================================================
# OPTIMIZER CONFIGURATION
# ================================================================
optimizer:
  lr: 0.0001                     # ← Same as successful runs
  type: "adam"
  weight_decay: 0.0
  betas: [0.9, 0.999]
  eps: 1.0e-08

# Learning rate scheduler - Cosine annealing over 80K
scheduler:
  type: "cosine"
  T_max: 80000                   # ← Full 80K training
  eta_min: 0.00001               # ← 10× reduction at end
  warmup_steps: 2000             # ← 1 epoch warmup

# ================================================================
# EXPERIMENT CONFIGURATION
# ================================================================
experiment:
  name: 'stage3_80k_sds_only_pure'

# ================================================================
# CHECKPOINT
# ================================================================
checkpoint:
  # Load Stage 2 trained checkpoint
  resume_from: 'outputs/stage2_official_cb20a1702_FIXED/checkpoints/last.ckpt'
  load_optimizer: false          # ← Fresh optimizer state
  load_scheduler: false          # ← Fresh scheduler state

# ================================================================
# CALLBACKS - CHECKPOINT SYSTEM
# ================================================================
callbacks:
  # Epoch-based: Best model selection
  checkpoint:
    monitor: "train_loss"
    mode: "min"
    save_top_k: 3                # ← Keep top 3 checkpoints
    every_n_epochs: 10           # ← Save every 10 epochs (4 times total)
    save_last: true              # ← Always save final checkpoint
    dirpath: "checkpoints"
    filename: "epoch{epoch:02d}-loss{loss:.4f}"

  # Step-based checkpoint - More granular
  checkpoint_steps:
    monitor: null
    mode: "min"
    save_top_k: -1               # ← Save all step checkpoints
    every_n_train_steps: 2000    # ← Every 2000 steps (40 checkpoints total)
    save_last: false
    filename: "step{step:05d}"
    save_on_train_epoch_end: false
    verbose: true
