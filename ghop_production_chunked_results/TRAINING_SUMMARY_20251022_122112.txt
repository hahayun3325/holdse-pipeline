================================================================================
                    HOLDSE TRAINING SESSION SUMMARY
================================================================================

Generated: Wed Oct 22 12:24:52 PM CDT 2025
Training Session ID: 20251022_122112

================================================================================
QUICK REFERENCE
================================================================================

Training Run ID:        d2d5f9756
Training Status:        INCOMPLETE
Epochs Completed:       24 / 100
Successful Chunks:      2 / 9

Checkpoint Location:    logs/d2d5f9756/checkpoints/
Final Checkpoint:       logs/d2d5f9756/checkpoints/last.ckpt

Config File:            confs/ghop_production_chunked_20251022_122112.yaml
Master Log:             ../ghop_production_chunked_results/chunked_training_20251022_122112.txt

================================================================================
TRAINING CONFIGURATION
================================================================================

Strategy:               12-epoch chunked training
Chunk Size:             12 epochs per chunk
Total Chunks:           9
Target Epochs:          100

CUDA Configuration:     PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
Memory Fixes Applied:
  ✓ CUDA fragmentation prevention (max_split_size_mb:128)
  ✓ torch.zeros explicit allocation
  ✓ 12-epoch safe chunking
  ✓ Natural process exit (no force-kill)

Dataset:                ghop_bottle_1
Batch Size:             1
Pixels Per Batch:       512
GPU ID:                 0

================================================================================
TRAINING TIMELINE
================================================================================

Start Time:             Wed Oct 22 12:21:12 PM CDT 2025
End Time:               Wed Oct 22 12:24:52 PM CDT 2025
Total Duration:         0h 3m 40s


Chunk-by-Chunk Breakdown:
-------------------------
  Chunk 0: Epochs 0 → 12
    Status: ❌ FAILED
    Log: ../ghop_production_chunked_results/chunk_0_epochs_0_12_20251022_122112.log

  Chunk 1: Epochs 12 → 24
    Status: ❌ FAILED
    Log: ../ghop_production_chunked_results/chunk_1_epochs_12_24_20251022_122157.log

  Chunk 2: Epochs 24 → 36
    Status: ❌ FAILED (OOM)
    Log: ../ghop_production_chunked_results/chunk_2_epochs_24_36_20251022_122317.log

  Chunk 3: Not started

  Chunk 4: Not started

  Chunk 5: Not started

  Chunk 6: Not started

  Chunk 7: Not started

  Chunk 8: Not started


================================================================================
CHECKPOINT INFORMATION
================================================================================

Run ID Tracking File:   ../ghop_production_chunked_results/current_run_id_20251022_122112.txt
Training Run ID:        d2d5f9756

Checkpoint Directory:   logs/d2d5f9756/

Available Checkpoints:
total 166M
-rw-rw-r-- 1 fredcui fredcui 166M Oct 22 12:23 last.ckpt

Final Checkpoint Info:
  Checkpoint Epoch: 24
  Global Step: 1320
  Model Parameters: 1567

================================================================================
GPU INFORMATION
================================================================================

GPU Configuration:
  GPU: Field
  Total Memory: "cuda_version"
  Driver Version: is
  CUDA Version: not
  GPU: 
  Total Memory: 
  Driver Version: 
  CUDA Version: 

Final GPU Memory Status:
  Used: 15, MB
  Free: 24097 MB

================================================================================
OUTPUT FILES AND LOGS
================================================================================

Results Directory:      ../ghop_production_chunked_results/

Master Log:             ../ghop_production_chunked_results/chunked_training_20251022_122112.txt
Summary File:           ../ghop_production_chunked_results/TRAINING_SUMMARY_20251022_122112.txt (this file)
Run ID File:            ../ghop_production_chunked_results/current_run_id_20251022_122112.txt

Chunk Logs:
  Chunk 0: ../ghop_production_chunked_results/chunk_0_epochs_0_12_20251022_122112.log
  Chunk 1: ../ghop_production_chunked_results/chunk_1_epochs_12_24_20251022_122157.log
  Chunk 2: ../ghop_production_chunked_results/chunk_2_epochs_24_36_20251022_122317.log

================================================================================
TRAINING OUTCOME
================================================================================

Status:                 INCOMPLETE
Epochs Completed:       24 / 100
Success Rate:           2 / 9 chunks (22%)

⚠️  TRAINING INCOMPLETE

To Resume Training:
  1. Check the last successful chunk log for errors
  2. Ensure GPU has sufficient memory
  3. Resume from last checkpoint:

     bash scripts/train_ghop_production_chunked.sh

  The script will automatically detect and resume from:
     logs/d2d5f9756/checkpoints/last.ckpt


================================================================================
TROUBLESHOOTING
================================================================================

If training failed:

1. Check GPU memory usage:
   nvidia-smi

2. Review the last chunk log for errors:
   tail -100 ../ghop_production_chunked_results/chunk_2_*.log

3. Verify CUDA configuration:
   echo $PYTORCH_CUDA_ALLOC_CONF

4. Check checkpoint integrity:
   python -c "import torch; ckpt = torch.load('logs/d2d5f9756/checkpoints/last.ckpt'); print(ckpt.keys())"

5. View master log:
   less ../ghop_production_chunked_results/chunked_training_20251022_122112.txt

Common Issues:
  - OOM at epoch 17: CUDA config not set (should be max_split_size_mb:128)
  - Wrong checkpoint loaded: Check run ID in ../ghop_production_chunked_results/current_run_id_20251022_122112.txt
  - Checkpoint not found: Verify logs/d2d5f9756/checkpoints/ exists

================================================================================
SYSTEM INFORMATION
================================================================================

Hostname:               hahayun
User:                   fredcui
Working Directory:      /home/fredcui/Projects/holdse/code
Python Version:         Python 3.8.20
PyTorch Version:        1.9.1+cu111

Environment Variables:
  PYTORCH_CUDA_ALLOC_CONF: max_split_size_mb:128
  CUDA_VISIBLE_DEVICES: Not set

================================================================================
END OF SUMMARY
================================================================================

For detailed logs, see: ../ghop_production_chunked_results/chunked_training_20251022_122112.txt
For per-chunk logs, see: ../ghop_production_chunked_results/chunk_*.log

Generated at: Wed Oct 22 12:24:53 PM CDT 2025
================================================================================
